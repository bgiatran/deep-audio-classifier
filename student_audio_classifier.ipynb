{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Student Audio Classifier (Capuchinbird Detection)\n",
    "This notebook was made by a student (me!) trying to figure out audio classification."
   ],
   "id": "a04589ee37641f3d"
  },
  {
   "cell_type": "markdown",
   "id": "651898a8",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "id": "fbf45b01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T17:58:27.122394Z",
     "start_time": "2025-07-11T17:58:23.530960Z"
    }
   },
   "source": "!pip install tensorflow tensorflow-io matplotlib",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: tensorflow-io in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (0.31.0)\n",
      "Requirement already satisfied: matplotlib in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (3.9.4)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from tensorflow) (5.29.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from tensorflow) (2.32.4)\n",
      "Requirement already satisfied: setuptools in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from tensorflow) (49.2.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from tensorflow) (4.14.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from tensorflow) (1.73.1)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from tensorflow) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from tensorflow) (0.31.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.7.9)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.8.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from matplotlib) (4.58.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from matplotlib) (6.5.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.23.0)\n",
      "Requirement already satisfied: rich in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
      "Requirement already satisfied: namex in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.19.0->tensorflow) (8.7.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\development\\deep-audio-classifier\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "240549ac",
   "metadata": {},
   "source": [
    "## Step 2: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "id": "13646ae0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T17:59:54.453493Z",
     "start_time": "2025-07-11T17:59:48.325008Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPooling2D\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical"
   ],
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtensorflow_io\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtfio\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Sequential\n",
      "File \u001B[1;32mC:\\development\\deep-audio-classifier\\venv\\lib\\site-packages\\tensorflow\\__init__.py:49\u001B[0m\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m tf2 \u001B[38;5;28;01mas\u001B[39;00m _tf2\n\u001B[0;32m     47\u001B[0m _tf2\u001B[38;5;241m.\u001B[39menable()\n\u001B[1;32m---> 49\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_api\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m __internal__\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_api\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m __operators__\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_api\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m audio\n",
      "File \u001B[1;32mC:\\development\\deep-audio-classifier\\venv\\lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py:8\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01msys\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m_sys\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_api\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m__internal__\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m autograph\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_api\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m__internal__\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m decorator\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_api\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m__internal__\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m dispatch\n",
      "File \u001B[1;32mC:\\development\\deep-audio-classifier\\venv\\lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\autograph\\__init__.py:8\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01msys\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m_sys\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mautograph\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mag_ctx\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m control_status_ctx \u001B[38;5;66;03m# line: 34\u001B[39;00m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mautograph\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mimpl\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m tf_convert \u001B[38;5;66;03m# line: 493\u001B[39;00m\n",
      "File \u001B[1;32mC:\\development\\deep-audio-classifier\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\core\\ag_ctx.py:21\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01minspect\u001B[39;00m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mthreading\u001B[39;00m\n\u001B[1;32m---> 21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mautograph\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ag_logging\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutil\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtf_export\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m tf_export\n\u001B[0;32m     25\u001B[0m stacks \u001B[38;5;241m=\u001B[39m threading\u001B[38;5;241m.\u001B[39mlocal()\n",
      "File \u001B[1;32mC:\\development\\deep-audio-classifier\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\utils\\__init__.py:17\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# limitations under the License.\u001B[39;00m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# ==============================================================================\u001B[39;00m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;124;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001B[39;00m\n\u001B[1;32m---> 17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mautograph\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcontext_managers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m control_dependency_on_returns\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mautograph\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmisc\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m alias_tensors\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mautograph\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtensor_list\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m dynamic_list_append\n",
      "File \u001B[1;32mC:\\development\\deep-audio-classifier\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\utils\\context_managers.py:19\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;124;03m\"\"\"Various context managers.\"\"\"\u001B[39;00m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mcontextlib\u001B[39;00m\n\u001B[1;32m---> 19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ops\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m tensor_array_ops\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mcontrol_dependency_on_returns\u001B[39m(return_value):\n",
      "File \u001B[1;32mC:\\development\\deep-audio-classifier\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:5929\u001B[0m\n\u001B[0;32m   5923\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mLookupError\u001B[39;00m:\n\u001B[0;32m   5924\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   5927\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mget_to_proto_function\u001B[39m(\n\u001B[0;32m   5928\u001B[0m     collection_name,\n\u001B[1;32m-> 5929\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[43mOptional\u001B[49m\u001B[43m[\u001B[49m\u001B[43mCallable\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[43mAny\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmessage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mMessage\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m:\n\u001B[0;32m   5930\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Returns the to_proto function for collection_name.\"\"\"\u001B[39;00m\n\u001B[0;32m   5931\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\typing.py:243\u001B[0m, in \u001B[0;36m_tp_cache.<locals>.inner\u001B[1;34m(*args, **kwds)\u001B[0m\n\u001B[0;32m    241\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m    242\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m  \u001B[38;5;66;03m# All real errors (not unhashable args) are raised below.\u001B[39;00m\n\u001B[1;32m--> 243\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\typing.py:316\u001B[0m, in \u001B[0;36m_SpecialForm.__getitem__\u001B[1;34m(self, parameters)\u001B[0m\n\u001B[0;32m    314\u001B[0m \u001B[38;5;129m@_tp_cache\u001B[39m\n\u001B[0;32m    315\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, parameters):\n\u001B[1;32m--> 316\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\typing.py:433\u001B[0m, in \u001B[0;36mOptional\u001B[1;34m(self, parameters)\u001B[0m\n\u001B[0;32m    428\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Optional type.\u001B[39;00m\n\u001B[0;32m    429\u001B[0m \n\u001B[0;32m    430\u001B[0m \u001B[38;5;124;03mOptional[X] is equivalent to Union[X, None].\u001B[39;00m\n\u001B[0;32m    431\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    432\u001B[0m arg \u001B[38;5;241m=\u001B[39m _type_check(parameters, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m requires a single type.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 433\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mUnion\u001B[49m\u001B[43m[\u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mtype\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\typing.py:243\u001B[0m, in \u001B[0;36m_tp_cache.<locals>.inner\u001B[1;34m(*args, **kwds)\u001B[0m\n\u001B[0;32m    241\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m    242\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m  \u001B[38;5;66;03m# All real errors (not unhashable args) are raised below.\u001B[39;00m\n\u001B[1;32m--> 243\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\typing.py:316\u001B[0m, in \u001B[0;36m_SpecialForm.__getitem__\u001B[1;34m(self, parameters)\u001B[0m\n\u001B[0;32m    314\u001B[0m \u001B[38;5;129m@_tp_cache\u001B[39m\n\u001B[0;32m    315\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, parameters):\n\u001B[1;32m--> 316\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\typing.py:421\u001B[0m, in \u001B[0;36mUnion\u001B[1;34m(self, parameters)\u001B[0m\n\u001B[0;32m    419\u001B[0m msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnion[arg, ...]: each arg must be a type.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    420\u001B[0m parameters \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(_type_check(p, msg) \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m parameters)\n\u001B[1;32m--> 421\u001B[0m parameters \u001B[38;5;241m=\u001B[39m \u001B[43m_remove_dups_flatten\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    422\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(parameters) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    423\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parameters[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\typing.py:215\u001B[0m, in \u001B[0;36m_remove_dups_flatten\u001B[1;34m(parameters)\u001B[0m\n\u001B[0;32m    213\u001B[0m         params\u001B[38;5;241m.\u001B[39mappend(p)\n\u001B[0;32m    214\u001B[0m \u001B[38;5;66;03m# Weed out strict duplicates, preserving the first of each occurrence.\u001B[39;00m\n\u001B[1;32m--> 215\u001B[0m all_params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mset\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    216\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(all_params) \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mlen\u001B[39m(params):\n\u001B[0;32m    217\u001B[0m     new_params \u001B[38;5;241m=\u001B[39m []\n",
      "\u001B[1;31mTypeError\u001B[0m: unhashable type: 'list'"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "b300633a",
   "metadata": {},
   "source": [
    "## Step 3: Load One Sample Audio"
   ]
  },
  {
   "cell_type": "code",
   "id": "61b3b1d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T17:59:54.599606600Z",
     "start_time": "2025-07-09T16:30:05.782884Z"
    }
   },
   "source": [
    "CAPUCHIN_FILE = \"audio/Parsed_Capuchinbird_Clips/XC3776-3.wav\"\n",
    "NOT_CAPUCHIN_FILE = \"audio/Parsed_Not_Capuchinbird_Clips/xxx.wav\""
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "014e91c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T17:59:54.739148200Z",
     "start_time": "2025-07-09T16:30:05.811865Z"
    }
   },
   "source": [
    "def load_wav_16k_mono(filename):\n",
    "    file_contents = tf.io.read_file(filename)\n",
    "    wav, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1)\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "    return wav"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "220faefb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T17:59:54.767142500Z",
     "start_time": "2025-07-09T16:30:05.845492Z"
    }
   },
   "source": [
    "wave = load_wav_16k_mono(CAPUCHIN_FILE)\n",
    "nwave = load_wav_16k_mono(NOT_CAPUCHIN_FILE)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(wave, label='Capuchinbird')\n",
    "plt.plot(nwave, label='Not Capuchin')\n",
    "plt.legend()\n",
    "plt.title('Waveforms')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "in user code:\n\n    File \"C:\\development\\deep-audio-classifier\\venv\\lib\\site-packages\\tensorflow_io\\python\\ops\\audio_ops.py\", line 458, in f\n        return core_ops.io_audio_resample(\n    File \"C:\\development\\deep-audio-classifier\\venv\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py\", line 88, in __getattr__\n        return getattr(self._load(), attrb)\n    File \"C:\\development\\deep-audio-classifier\\venv\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py\", line 84, in _load\n        self._mod = _load_library(self._library)\n    File \"C:\\development\\deep-audio-classifier\\venv\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py\", line 69, in _load_library\n        raise NotImplementedError(\n\n    NotImplementedError: unable to open file: libtensorflow_io.so, from paths: ['C:\\\\development\\\\deep-audio-classifier\\\\venv\\\\lib\\\\site-packages\\\\tensorflow_io\\\\python\\\\ops\\\\libtensorflow_io.so']\n    caused by: ['C:\\\\development\\\\deep-audio-classifier\\\\venv\\\\lib\\\\site-packages\\\\tensorflow_io\\\\python\\\\ops\\\\libtensorflow_io.so not found']\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNotImplementedError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m wave \u001B[38;5;241m=\u001B[39m \u001B[43mload_wav_16k_mono\u001B[49m\u001B[43m(\u001B[49m\u001B[43mCAPUCHIN_FILE\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m nwave \u001B[38;5;241m=\u001B[39m load_wav_16k_mono(NOT_CAPUCHIN_FILE)\n\u001B[0;32m      4\u001B[0m plt\u001B[38;5;241m.\u001B[39mfigure(figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m4\u001B[39m))\n",
      "Cell \u001B[1;32mIn[4], line 6\u001B[0m, in \u001B[0;36mload_wav_16k_mono\u001B[1;34m(filename)\u001B[0m\n\u001B[0;32m      4\u001B[0m wav \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39msqueeze(wav, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m      5\u001B[0m sample_rate \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mcast(sample_rate, dtype\u001B[38;5;241m=\u001B[39mtf\u001B[38;5;241m.\u001B[39mint64)\n\u001B[1;32m----> 6\u001B[0m wav \u001B[38;5;241m=\u001B[39m \u001B[43mtfio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maudio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresample\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwav\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrate_in\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_rate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrate_out\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m16000\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m wav\n",
      "File \u001B[1;32mC:\\development\\deep-audio-classifier\\venv\\lib\\site-packages\\tensorflow_io\\python\\ops\\audio_ops.py:462\u001B[0m, in \u001B[0;36mresample\u001B[1;34m(input, rate_in, rate_out, name)\u001B[0m\n\u001B[0;32m    457\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mf\u001B[39m(i):\n\u001B[0;32m    458\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m core_ops\u001B[38;5;241m.\u001B[39mio_audio_resample(\n\u001B[0;32m    459\u001B[0m         i, rate_in\u001B[38;5;241m=\u001B[39mrate_in, rate_out\u001B[38;5;241m=\u001B[39mrate_out, name\u001B[38;5;241m=\u001B[39mname\n\u001B[0;32m    460\u001B[0m     )\n\u001B[1;32m--> 462\u001B[0m value \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvectorized_map\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    464\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mg1\u001B[39m():\n\u001B[0;32m    465\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tf\u001B[38;5;241m.\u001B[39msqueeze(value, [\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m])\n",
      "File \u001B[1;32mC:\\development\\deep-audio-classifier\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\parallel_for\\control_flow_ops.py:578\u001B[0m, in \u001B[0;36mvectorized_map\u001B[1;34m(fn, elems, fallback_to_while_loop, warn)\u001B[0m\n\u001B[0;32m    575\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    576\u001B[0m   batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmax\u001B[39m(static_first_dims)\n\u001B[1;32m--> 578\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpfor\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    579\u001B[0m \u001B[43m    \u001B[49m\u001B[43mloop_fn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    580\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    581\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfallback_to_while_loop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfallback_to_while_loop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    582\u001B[0m \u001B[43m    \u001B[49m\u001B[43mwarn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwarn\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\development\\deep-audio-classifier\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\parallel_for\\control_flow_ops.py:228\u001B[0m, in \u001B[0;36mpfor\u001B[1;34m(loop_fn, iters, fallback_to_while_loop, parallel_iterations, warn)\u001B[0m\n\u001B[0;32m    225\u001B[0m     def_function\u001B[38;5;241m.\u001B[39mrun_functions_eagerly(\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m    226\u001B[0m   f \u001B[38;5;241m=\u001B[39m def_function\u001B[38;5;241m.\u001B[39mfunction(f)\n\u001B[1;32m--> 228\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    229\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m functions_run_eagerly \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    230\u001B[0m   def_function\u001B[38;5;241m.\u001B[39mrun_functions_eagerly(functions_run_eagerly)\n",
      "File \u001B[1;32mC:\\development\\deep-audio-classifier\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m--> 153\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    155\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileja74s61q.py:17\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__f\u001B[1;34m()\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     16\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m---> 17\u001B[0m     retval_ \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(_pfor_impl), (ag__\u001B[38;5;241m.\u001B[39mld(loop_fn), ag__\u001B[38;5;241m.\u001B[39mld(iters)), \u001B[38;5;28mdict\u001B[39m(fallback_to_while_loop\u001B[38;5;241m=\u001B[39mag__\u001B[38;5;241m.\u001B[39mld(fallback_to_while_loop), parallel_iterations\u001B[38;5;241m=\u001B[39mag__\u001B[38;5;241m.\u001B[39mld(parallel_iterations), warn\u001B[38;5;241m=\u001B[39mag__\u001B[38;5;241m.\u001B[39mld(warn)), fscope)\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[0;32m     19\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32mC:\\development\\deep-audio-classifier\\venv\\lib\\site-packages\\tensorflow_io\\python\\ops\\audio_ops.py:458\u001B[0m, in \u001B[0;36mresample.<locals>.f\u001B[1;34m(i)\u001B[0m\n\u001B[0;32m    457\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mf\u001B[39m(i):\n\u001B[1;32m--> 458\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcore_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mio_audio_resample\u001B[49m(\n\u001B[0;32m    459\u001B[0m         i, rate_in\u001B[38;5;241m=\u001B[39mrate_in, rate_out\u001B[38;5;241m=\u001B[39mrate_out, name\u001B[38;5;241m=\u001B[39mname\n\u001B[0;32m    460\u001B[0m     )\n",
      "File \u001B[1;32mC:\\development\\deep-audio-classifier\\venv\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py:88\u001B[0m, in \u001B[0;36mLazyLoader.__getattr__\u001B[1;34m(self, attrb)\u001B[0m\n\u001B[0;32m     87\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__getattr__\u001B[39m(\u001B[38;5;28mself\u001B[39m, attrb):\n\u001B[1;32m---> 88\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m, attrb)\n",
      "File \u001B[1;32mC:\\development\\deep-audio-classifier\\venv\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py:84\u001B[0m, in \u001B[0;36mLazyLoader._load\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     82\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_load\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m     83\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mod \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m---> 84\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mod \u001B[38;5;241m=\u001B[39m \u001B[43m_load_library\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_library\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     85\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mod\n",
      "File \u001B[1;32mC:\\development\\deep-audio-classifier\\venv\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py:69\u001B[0m, in \u001B[0;36m_load_library\u001B[1;34m(filename, lib)\u001B[0m\n\u001B[0;32m     67\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m (tf\u001B[38;5;241m.\u001B[39merrors\u001B[38;5;241m.\u001B[39mNotFoundError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     68\u001B[0m         errs\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28mstr\u001B[39m(e))\n\u001B[1;32m---> 69\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\n\u001B[0;32m     70\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124munable to open file: \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     71\u001B[0m     \u001B[38;5;241m+\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfilename\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, from paths: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfilenames\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mcaused by: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00merrs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     72\u001B[0m )\n",
      "\u001B[1;31mNotImplementedError\u001B[0m: in user code:\n\n    File \"C:\\development\\deep-audio-classifier\\venv\\lib\\site-packages\\tensorflow_io\\python\\ops\\audio_ops.py\", line 458, in f\n        return core_ops.io_audio_resample(\n    File \"C:\\development\\deep-audio-classifier\\venv\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py\", line 88, in __getattr__\n        return getattr(self._load(), attrb)\n    File \"C:\\development\\deep-audio-classifier\\venv\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py\", line 84, in _load\n        self._mod = _load_library(self._library)\n    File \"C:\\development\\deep-audio-classifier\\venv\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py\", line 69, in _load_library\n        raise NotImplementedError(\n\n    NotImplementedError: unable to open file: libtensorflow_io.so, from paths: ['C:\\\\development\\\\deep-audio-classifier\\\\venv\\\\lib\\\\site-packages\\\\tensorflow_io\\\\python\\\\ops\\\\libtensorflow_io.so']\n    caused by: ['C:\\\\development\\\\deep-audio-classifier\\\\venv\\\\lib\\\\site-packages\\\\tensorflow_io\\\\python\\\\ops\\\\libtensorflow_io.so not found']\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "a18a1c57",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "Now that we loaded our audio, we’ll move on to making datasets, building spectrograms, and training a model! 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6eb1d7",
   "metadata": {},
   "source": [
    "## Step 4: Make TensorFlow Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f942876",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "POS = os.path.join('audio', 'Parsed_Capuchinbird_Clips')\n",
    "NEG = os.path.join('audio', 'Parsed_Not_Capuchinbird_Clips')\n",
    "\n",
    "pos_ds = tf.data.Dataset.list_files(POS + '/*.wav')\n",
    "neg_ds = tf.data.Dataset.list_files(NEG + '/*.wav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3092ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assign labels (1 for capuchin, 0 for not)\n",
    "positives = pos_ds.map(lambda x: (x, tf.constant(1)))\n",
    "negatives = neg_ds.map(lambda x: (x, tf.constant(0)))\n",
    "\n",
    "# Combine datasets\n",
    "all_ds = positives.concatenate(negatives)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843a589c",
   "metadata": {},
   "source": [
    "## Step 5: Convert WAV to Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3423d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess(file_path, label):\n",
    "    wav = load_wav_16k_mono(file_path)\n",
    "    wav = wav[:48000]\n",
    "    zero_padding = tf.zeros([48000] - tf.shape(wav), dtype=tf.float32)\n",
    "    wav = tf.concat([zero_padding, wav], 0)\n",
    "    spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32)\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    spectrogram = tf.expand_dims(spectrogram, axis=2)\n",
    "    return spectrogram, label\n",
    "\n",
    "# Map function to dataset\n",
    "all_ds = all_ds.map(preprocess)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b67f4a",
   "metadata": {},
   "source": [
    "## Step 6: Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883c944a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_ds = all_ds.cache().shuffle(1000).batch(16).prefetch(tf.data.AUTOTUNE)\n",
    "train = all_ds.take(36)\n",
    "test = all_ds.skip(36).take(15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cffb16",
   "metadata": {},
   "source": [
    "## Step 7: Build a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab55dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    tf.keras.Input(shape=(64, 64, 1)),\n",
    "    Conv2D(16, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc9ee91",
   "metadata": {},
   "source": [
    "## Step 8: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d91727c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hist = model.fit(train, epochs=4, validation_data=test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a675057",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(hist.history['loss'], label='loss')\n",
    "plt.plot(hist.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.title('Loss over Epochs')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0c3f05",
   "metadata": {},
   "source": [
    "## Step 9: Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7d65d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test, y_test = test.as_numpy_iterator().next()\n",
    "yhat = model.predict(X_test)\n",
    "print(\"Raw predictions:\", yhat[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9591a801",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert probabilities to binary class labels\n",
    "yhat_classes = [1 if p > 0.5 else 0 for p in yhat]\n",
    "print(\"Predicted classes:\", yhat_classes[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ae9ff5",
   "metadata": {},
   "source": [
    "## Step 10: Save Model and Done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a440e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.save('models/student_capuchin_model.h5')\n",
    "print(\"Model saved!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
